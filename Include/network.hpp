#pragma once
#include "model_b_15_params.h"
#include "model_w_15_params.h"
#include "qnnet.hpp"
#include <algorithm>
#include <cstdint>

namespace AlphaGomoku {

  struct GodNet {
    using InputTensor = Tensor<uint8_t, 3, 15, 15>;
    using RetType = std::pair<Vec<SCALE_T, 15 * 15>&, SCALE_T&>;
    virtual RetType feed(const InputTensor& input)  = 0;
    virtual RetType output() = 0;
  };

namespace Black {
    using namespace model_b_15_params;
    inline constexpr WEIGHT_T Q_ZERO = model_w_15_params::input_zero_point;
    inline constexpr WEIGHT_T Q_ONE = std::clamp(const_round_half_away_from_zero(1.0f/input_scale), WEIGHT_MIN, WEIGHT_MAX);
    inline constexpr WEIGHT_T Q_NEG_ONE = std::clamp(const_round_half_away_from_zero(-1.0f/input_scale), WEIGHT_MIN, WEIGHT_MAX);

  // Parameter declarations

struct QuantizedNetwork : GodNet {
public:
    QuantizedNetwork();
    RetType feed(const Tensor<uint8_t, 3, 15, 15>& input) override;
    static constexpr size_t BOARD_SIZE = 15;
    RetType output() override{
      return  std::pair<Vec<SCALE_T, BOARD_SIZE * BOARD_SIZE>&, SCALE_T&>(pi, v);
    }
    
private:
    // Network layers
    QLinearConv<input_scale, input_zero_point, functional_1_conv2d_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_1_BiasAdd_0_scale, functional_1_conv2d_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 3, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_conv2d_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_conv2d_1_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_batch_normalization_1_batchnorm_add_1_0_scale, functional_1_batch_normalization_1_batchnorm_add_1_0_zero_point, functional_1_conv2d_1_2_convolution_ReadVariableOp_0_scale, functional_1_conv2d_1_2_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_1_2_BiasAdd_0_scale, functional_1_conv2d_1_2_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_conv2d_1_2_BiasAdd_quant;
    BNop</* a_scale */ functional_1_conv2d_1_2_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_1_2_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_1_2_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_1_2_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_1_2_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_1_2_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_1_2_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_1_2_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_1_2_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_1_2_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_1_2_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_1_2_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_1_2_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_1_2_batchnorm_add_1_quant;
    QLinearConv<functional_1_batch_normalization_1_2_batchnorm_add_1_0_scale, functional_1_batch_normalization_1_2_batchnorm_add_1_0_zero_point, functional_1_conv2d_2_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_2_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_2_1_BiasAdd_0_scale, functional_1_conv2d_2_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_conv2d_2_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_conv2d_2_1_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_2_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_2_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_2_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_2_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_2_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_2_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_2_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_2_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_2_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_2_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_2_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_2_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_2_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_add_1_Add_0_scale, functional_1_add_1_Add_0_zero_point, functional_1_conv2d_3_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_3_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_3_1_BiasAdd_0_scale, functional_1_conv2d_3_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_conv2d_3_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_conv2d_3_1_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_3_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_3_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_3_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_3_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_3_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_3_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_3_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_3_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_3_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_3_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_3_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_3_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_3_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_batch_normalization_3_1_batchnorm_add_1_0_scale, functional_1_batch_normalization_3_1_batchnorm_add_1_0_zero_point, functional_1_conv2d_4_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_4_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_4_1_BiasAdd_0_scale, functional_1_conv2d_4_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_conv2d_4_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_conv2d_4_1_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_4_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_4_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_4_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_4_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_4_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_4_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_4_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_4_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_4_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_4_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_4_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_4_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_4_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_add_1_2_Add_0_scale, functional_1_add_1_2_Add_0_zero_point, functional_1_conv2d_5_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_5_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_5_1_BiasAdd_0_scale, functional_1_conv2d_5_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_conv2d_5_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_conv2d_5_1_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_5_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_5_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_5_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_5_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_5_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_5_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_5_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_5_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_5_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_5_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_5_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_5_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_5_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_batch_normalization_5_1_batchnorm_add_1_0_scale, functional_1_batch_normalization_5_1_batchnorm_add_1_0_zero_point, functional_1_conv2d_6_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_6_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_6_1_BiasAdd_0_scale, functional_1_conv2d_6_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_conv2d_6_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_conv2d_6_1_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_6_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_6_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_6_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_6_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_6_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_6_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_6_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_6_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_6_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_6_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_6_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_6_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_6_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_add_2_1_Add_0_scale, functional_1_add_2_1_Add_0_zero_point, functional_1_conv2d_7_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_7_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_7_1_BiasAdd_0_scale, functional_1_conv2d_7_1_BiasAdd_0_zero_point, /* Filters */ 2, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 1, /* KernelWidth */ 1> functional_1_conv2d_7_1_BiasAdd_quant;
    QLinearConv<functional_1_add_2_1_Add_0_scale, functional_1_add_2_1_Add_0_zero_point, functional_1_conv2d_8_1_convolution_ReadVariableOp_0_scale, functional_1_conv2d_8_1_convolution_ReadVariableOp_0_zero_point, functional_1_conv2d_8_1_Add_0_scale, functional_1_conv2d_8_1_Add_0_zero_point, /* Filters */ 1, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 1, /* KernelWidth */ 1> functional_1_conv2d_8_1_convolution_quant;
    BNop</* a_scale */ functional_1_conv2d_7_1_BiasAdd_0_scale, /* a_zp */ functional_1_conv2d_7_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_batch_normalization_7_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_7_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_7_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_7_1_batchnorm_mul_1_0_zero_point, /* C */ 2, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_7_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_conv2d_8_1_Add_0_scale, /* a_zp */ functional_1_conv2d_8_1_Add_0_zero_point, /* b_scale */ functional_1_batch_normalization_8_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_batch_normalization_8_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_batch_normalization_8_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_batch_normalization_8_1_batchnorm_mul_1_0_zero_point, /* C */ 1, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_batch_normalization_8_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_7_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_7_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_7_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_7_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_7_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_7_1_batchnorm_add_1_0_zero_point, /* C */ 2, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_7_1_batchnorm_add_1_quant;
    BNop</* a_scale */ functional_1_batch_normalization_8_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_batch_normalization_8_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_batch_normalization_8_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_batch_normalization_8_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_batch_normalization_8_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_batch_normalization_8_1_batchnorm_add_1_0_zero_point, /* C */ 1, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_batch_normalization_8_1_batchnorm_add_1_quant;
    QGemm</* a_scale */ functional_1_batch_normalization_7_1_batchnorm_add_1_0_scale, /* a_zp */ functional_1_batch_normalization_7_1_batchnorm_add_1_0_zero_point, /* b_scale */ functional_1_dense_3_Cast_ReadVariableOp_0_scale, /* b_zp */ functional_1_dense_3_Cast_ReadVariableOp_0_zero_point, /* c_scale */ functional_1_dense_3_BiasAdd_0_scale, /* c_zp */ functional_1_dense_3_BiasAdd_0_zero_point, /* FlattenLen */ 450, /* Filters */ 225, /* Requant */ false> gemm_quant;
    QGemm</* a_scale */ functional_1_batch_normalization_8_1_batchnorm_add_1_0_scale, /* a_zp */ functional_1_batch_normalization_8_1_batchnorm_add_1_0_zero_point, /* b_scale */ functional_1_dense_1_1_Cast_ReadVariableOp_0_scale, /* b_zp */ functional_1_dense_1_1_Cast_ReadVariableOp_0_zero_point, /* c_scale */ functional_1_dense_1_1_BiasAdd_0_scale, /* c_zp */ functional_1_dense_1_1_BiasAdd_0_zero_point, /* FlattenLen */ 225, /* Filters */ 32, /* Requant */ true> gemm_token_0_quant;
    QGemm</* a_scale */ functional_1_dense_1_1_BiasAdd_0_scale, /* a_zp */ functional_1_dense_1_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_dense_2_1_Cast_ReadVariableOp_0_scale, /* b_zp */ functional_1_dense_2_1_Cast_ReadVariableOp_0_zero_point, /* c_scale */ functional_1_dense_2_1_Add_0_scale, /* c_zp */ functional_1_dense_2_1_Add_0_zero_point, /* FlattenLen */ 32, /* Filters */ 1, /* Requant */ false> gemm_token_1_quant;

    Vec<SCALE_T, BOARD_SIZE * BOARD_SIZE> pi;
    SCALE_T v;
};

} // namespace Black

namespace White {
    using namespace model_w_15_params;
    inline constexpr WEIGHT_T Q_ZERO = model_w_15_params::input_zero_point;
    inline constexpr WEIGHT_T Q_ONE = std::clamp(const_round_half_away_from_zero(1.0f/input_scale), WEIGHT_MIN, WEIGHT_MAX);
    inline constexpr WEIGHT_T Q_NEG_ONE = std::clamp(const_round_half_away_from_zero(-1.0f/input_scale), WEIGHT_MIN, WEIGHT_MAX);

  // Parameter declarations

struct QuantizedNetwork : GodNet {
public:
    QuantizedNetwork();
    RetType feed(const Tensor<uint8_t, 3, 15, 15>& input) override;
    static constexpr size_t BOARD_SIZE = 15;
    RetType output() override{
      return  std::pair<Vec<SCALE_T, BOARD_SIZE * BOARD_SIZE>&, SCALE_T&>(pi, v);
    }
    
private:
    // Network layers
    QLinearConv<input_scale, input_zero_point, functional_1_1_conv2d_9_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_9_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_9_1_BiasAdd_0_scale, functional_1_1_conv2d_9_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 3, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_1_conv2d_9_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_9_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_9_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_9_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_9_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_9_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_9_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_9_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_9_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_9_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_9_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_9_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_9_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_9_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_9_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_1_batch_normalization_9_1_batchnorm_add_1_0_scale, functional_1_1_batch_normalization_9_1_batchnorm_add_1_0_zero_point, functional_1_1_conv2d_10_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_10_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_10_1_BiasAdd_0_scale, functional_1_1_conv2d_10_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_1_conv2d_10_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_10_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_10_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_10_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_10_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_10_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_10_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_10_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_10_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_10_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_10_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_10_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_10_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_10_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_10_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_1_batch_normalization_10_1_batchnorm_add_1_0_scale, functional_1_1_batch_normalization_10_1_batchnorm_add_1_0_zero_point, functional_1_1_conv2d_11_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_11_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_11_1_BiasAdd_0_scale, functional_1_1_conv2d_11_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_1_conv2d_11_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_11_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_11_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_11_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_11_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_11_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_11_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_11_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_11_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_11_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_11_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_11_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_11_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_11_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_11_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_1_add_3_1_Add_0_scale, functional_1_1_add_3_1_Add_0_zero_point, functional_1_1_conv2d_12_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_12_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_12_1_BiasAdd_0_scale, functional_1_1_conv2d_12_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_1_conv2d_12_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_12_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_12_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_12_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_12_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_12_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_12_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_12_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_12_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_12_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_12_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_12_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_12_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_12_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_12_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_1_batch_normalization_12_1_batchnorm_add_1_0_scale, functional_1_1_batch_normalization_12_1_batchnorm_add_1_0_zero_point, functional_1_1_conv2d_13_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_13_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_13_1_BiasAdd_0_scale, functional_1_1_conv2d_13_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_1_conv2d_13_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_13_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_13_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_13_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_13_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_13_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_13_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_13_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_13_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_13_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_13_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_13_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_13_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_13_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_13_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_1_add_4_1_Add_0_scale, functional_1_1_add_4_1_Add_0_zero_point, functional_1_1_conv2d_14_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_14_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_14_1_BiasAdd_0_scale, functional_1_1_conv2d_14_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_1_conv2d_14_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_14_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_14_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_14_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_14_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_14_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_14_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_14_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_14_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_14_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_14_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_14_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_14_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_14_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_14_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_1_batch_normalization_14_1_batchnorm_add_1_0_scale, functional_1_1_batch_normalization_14_1_batchnorm_add_1_0_zero_point, functional_1_1_conv2d_15_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_15_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_15_1_BiasAdd_0_scale, functional_1_1_conv2d_15_1_BiasAdd_0_zero_point, /* Filters */ 32, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 3, /* KernelWidth */ 3> functional_1_1_conv2d_15_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_15_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_15_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_15_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_15_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_15_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_15_1_batchnorm_mul_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_15_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_15_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_15_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_15_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_15_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_15_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_15_1_batchnorm_add_1_0_zero_point, /* C */ 32, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_15_1_batchnorm_add_1_quant;
    QLinearConv<functional_1_1_add_5_1_Add_0_scale, functional_1_1_add_5_1_Add_0_zero_point, functional_1_1_conv2d_17_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_17_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_17_1_Add_0_scale, functional_1_1_conv2d_17_1_Add_0_zero_point, /* Filters */ 1, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 1, /* KernelWidth */ 1> functional_1_1_conv2d_17_1_convolution_quant;
    QLinearConv<functional_1_1_add_5_1_Add_0_scale, functional_1_1_add_5_1_Add_0_zero_point, functional_1_1_conv2d_16_1_convolution_ReadVariableOp_0_scale, functional_1_1_conv2d_16_1_convolution_ReadVariableOp_0_zero_point, functional_1_1_conv2d_16_1_BiasAdd_0_scale, functional_1_1_conv2d_16_1_BiasAdd_0_zero_point, /* Filters */ 2, /* InputChannels */ 32, /* InputHeight */ 15, /* InputWidth */ 15, /* KernelHeight */ 1, /* KernelWidth */ 1> functional_1_1_conv2d_16_1_BiasAdd_quant;
    BNop</* a_scale */ functional_1_1_conv2d_17_1_Add_0_scale, /* a_zp */ functional_1_1_conv2d_17_1_Add_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_17_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_17_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_17_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_17_1_batchnorm_mul_1_0_zero_point, /* C */ 1, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_17_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_conv2d_16_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_conv2d_16_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_16_1_batchnorm_mul_0_scale, /* b_zp */ functional_1_1_batch_normalization_16_1_batchnorm_mul_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_16_1_batchnorm_mul_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_16_1_batchnorm_mul_1_0_zero_point, /* C */ 2, /* H */ 15, /* W */ 15, /* IsMul */ true> functional_1_1_batch_normalization_16_1_batchnorm_mul_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_17_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_17_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_17_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_17_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_17_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_17_1_batchnorm_add_1_0_zero_point, /* C */ 1, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_17_1_batchnorm_add_1_quant;
    BNop</* a_scale */ functional_1_1_batch_normalization_16_1_batchnorm_mul_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_16_1_batchnorm_mul_1_0_zero_point, /* b_scale */ functional_1_1_batch_normalization_16_1_batchnorm_sub_0_scale, /* b_zp */ functional_1_1_batch_normalization_16_1_batchnorm_sub_0_zero_point, /* c_scale */ functional_1_1_batch_normalization_16_1_batchnorm_add_1_0_scale, /* c_zp */ functional_1_1_batch_normalization_16_1_batchnorm_add_1_0_zero_point, /* C */ 2, /* H */ 15, /* W */ 15, /* IsMul */ false> functional_1_1_batch_normalization_16_1_batchnorm_add_1_quant;
    QGemm</* a_scale */ functional_1_1_batch_normalization_17_1_batchnorm_add_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_17_1_batchnorm_add_1_0_zero_point, /* b_scale */ functional_1_1_dense_4_1_Cast_ReadVariableOp_0_scale, /* b_zp */ functional_1_1_dense_4_1_Cast_ReadVariableOp_0_zero_point, /* c_scale */ functional_1_1_dense_4_1_BiasAdd_0_scale, /* c_zp */ functional_1_1_dense_4_1_BiasAdd_0_zero_point, /* FlattenLen */ 225, /* Filters */ 32, /* Requant */ true> gemm_quant;
    QGemm</* a_scale */ functional_1_1_batch_normalization_16_1_batchnorm_add_1_0_scale, /* a_zp */ functional_1_1_batch_normalization_16_1_batchnorm_add_1_0_zero_point, /* b_scale */ functional_1_1_dense_3_1_Cast_ReadVariableOp_0_scale, /* b_zp */ functional_1_1_dense_3_1_Cast_ReadVariableOp_0_zero_point, /* c_scale */ functional_1_1_dense_3_1_BiasAdd_0_scale, /* c_zp */ functional_1_1_dense_3_1_BiasAdd_0_zero_point, /* FlattenLen */ 450, /* Filters */ 225, /* Requant */ false> gemm_token_1_quant;
    QGemm</* a_scale */ functional_1_1_dense_4_1_BiasAdd_0_scale, /* a_zp */ functional_1_1_dense_4_1_BiasAdd_0_zero_point, /* b_scale */ functional_1_1_dense_5_1_Cast_ReadVariableOp_0_scale, /* b_zp */ functional_1_1_dense_5_1_Cast_ReadVariableOp_0_zero_point, /* c_scale */ functional_1_1_dense_5_1_Add_0_scale, /* c_zp */ functional_1_1_dense_5_1_Add_0_zero_point, /* FlattenLen */ 32, /* Filters */ 1, /* Requant */ false> gemm_token_0_quant;

    Vec<SCALE_T, BOARD_SIZE * BOARD_SIZE> pi;
    SCALE_T v;
};

} // namespace White
} // namespace AlphaGomoku
  